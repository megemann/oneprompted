{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "from IPython.display import HTML, Markdown, display\n",
    "from google.api_core import retry\n",
    "GOOGLE_API_KEY = \"AIzaSyBcpBqjxGuHqKQXf3iJhox6TEpqHZMKBog\"\n",
    "\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "genai.models.Models.generate_content = retry.Retry(\n",
    "    predicate=is_retriable)(genai.models.Models.generate_content)\n",
    "\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/gemini-2.0-flash-live-001\n"
     ]
    }
   ],
   "source": [
    "# List all available models from the genai client\n",
    "print(\"Available models:\")\n",
    "for model in client.models.list():\n",
    "    print(model.name)\n",
    "\n",
    "model = 'models/gemini-2.0-flash-lite-001' #same as the base model without fine tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you're talking to a 7-year-old child. Explain Artificial Intelligence (AI) in simple terms, using analogies and examples a child can easily understand. Break down complex concepts into bite-sized pieces. Explain what AI can do, provide three kid-friendly examples of AI in action (e.g., a robot that plays games, a smart toy, or a voice assistant). Avoid technical jargon. Your response should be no more than 200 words and formatted as a numbered list.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "def generate_response(prompt):\n",
    "    inputs = f'''You are a prompt engineering expert that transforms simple \n",
    "    prompts into more effective versions. Analyze the input prompt and create\n",
    "      an improved version that includes specific details, context, desired output format, \n",
    "      and any relevant constraints. Make the prompt clear, specific, and designed to \n",
    "      generate high-quality responses.\n",
    "      \n",
    "      Input Prompt: {prompt}\n",
    "\n",
    "      Respond ONLY with the text of the improved prompt, without any explanations, \n",
    "      introductions, or additional commentary.\n",
    "      '''\n",
    "\n",
    "    return client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=inputs).text\n",
    "\n",
    "print(generate_response('Explain AI to me like im a little kid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully with 1000 rows\n",
      "\n",
      "Dataset columns:\n",
      "- original_id\n",
      "- original_prompt\n",
      "- context\n",
      "- prompt\n",
      "\n",
      "First 5 rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_id</th>\n",
       "      <th>original_prompt</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140731</td>\n",
       "      <td>One-pot vegetarian pasta recipes for busy nights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One-pot vegetarian pasta recipes for busy nights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121053</td>\n",
       "      <td>We have the following blog content... what is ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We have the following blog content... what is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37805</td>\n",
       "      <td>how o sort element using merge sort technique ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>how o sort element using merge sort technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116016</td>\n",
       "      <td>make a javascript class \"GraphicLayer\" which i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>make a javascript class \"GraphicLayer\" which i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132819</td>\n",
       "      <td>!Please outline the steps to build an automate...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Please outline the steps to build an automated...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_id                                    original_prompt context  \\\n",
       "0       140731   One-pot vegetarian pasta recipes for busy nights     NaN   \n",
       "1       121053  We have the following blog content... what is ...     NaN   \n",
       "2        37805  how o sort element using merge sort technique ...     NaN   \n",
       "3       116016  make a javascript class \"GraphicLayer\" which i...     NaN   \n",
       "4       132819  !Please outline the steps to build an automate...     NaN   \n",
       "\n",
       "                                              prompt  \n",
       "0   One-pot vegetarian pasta recipes for busy nights  \n",
       "1  We have the following blog content... what is ...  \n",
       "2  how o sort element using merge sort technique ...  \n",
       "3  make a javascript class \"GraphicLayer\" which i...  \n",
       "4  Please outline the steps to build an automated...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the ShareGPT dataset from CSV\n",
    "try:\n",
    "    # Define the path to the CSV file\n",
    "    csv_path = \"../data/ShareGPT/separated_prompts_clean.csv\"\n",
    "    \n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df_sharegpt = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Display basic information about the dataset\n",
    "    print(f\"Dataset loaded successfully with {len(df_sharegpt)} rows\")\n",
    "    print(\"\\nDataset columns:\")\n",
    "    for col in df_sharegpt.columns:\n",
    "        print(f\"- {col}\")\n",
    "    \n",
    "    # Display the first few rows of the dataset\n",
    "    print(\"\\nFirst 5 rows of the dataset:\")\n",
    "    display(df_sharegpt.head())\n",
    "\n",
    "    df_sharegpt.drop(columns=['context', 'prompt'], inplace=True)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file at '../data/ShareGPT/separated_prompts_clean.csv' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the dataset: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating improved prompts for each original prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts:  10%|█         | 101/1000 [03:43<35:57,  2.40s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 rows. Saving batch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts:  20%|██        | 201/1000 [07:47<22:11,  1.67s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200 rows. Saving batch 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts:  30%|███       | 301/1000 [11:23<23:35,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 300 rows. Saving batch 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts:  40%|████      | 401/1000 [15:21<22:50,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 400 rows. Saving batch 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts:  50%|█████     | 501/1000 [18:59<19:46,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 rows. Saving batch 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts:  60%|██████    | 601/1000 [22:28<12:49,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 600 rows. Saving batch 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts:  70%|███████   | 701/1000 [26:08<06:39,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 700 rows. Saving batch 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts:  80%|████████  | 801/1000 [30:12<07:08,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 800 rows. Saving batch 8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts:  90%|█████████ | 901/1000 [34:05<04:50,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 900 rows. Saving batch 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts: 100%|██████████| 1000/1000 [38:01<00:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 rows. Saving batch 10...\n",
      "Completed generating 1000 improved prompts\n",
      "Final results saved to ../data/Flash2.0Responses/all_responses.csv\n",
      "\n",
      "Sample of results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_prompt</th>\n",
       "      <th>base_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One-pot vegetarian pasta recipes for busy nights</td>\n",
       "      <td>Write five unique one-pot vegetarian pasta rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We have the following blog content... what is ...</td>\n",
       "      <td>Analyze the provided blog content from GigSala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how o sort element using merge sort technique ...</td>\n",
       "      <td>Write a Java program that implements the Merge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     original_prompt  \\\n",
       "0   One-pot vegetarian pasta recipes for busy nights   \n",
       "1  We have the following blog content... what is ...   \n",
       "2  how o sort element using merge sort technique ...   \n",
       "\n",
       "                                       base_response  \n",
       "0  Write five unique one-pot vegetarian pasta rec...  \n",
       "1  Analyze the provided blog content from GigSala...  \n",
       "2  Write a Java program that implements the Merge...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the generate_response function to each original_prompt in the dataframe\n",
    "# This will create a new column 'base_response' with the improved prompts\n",
    "print(\"Generating improved prompts for each original prompt...\")\n",
    "\n",
    "# Import tqdm for progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define a function to safely apply generate_response\n",
    "def safe_generate_response(prompt):\n",
    "    try:\n",
    "        return generate_response(prompt)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing prompt: {str(e)[:100]}...\")\n",
    "        return \"Error generating response\"\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(\"../data/Flash2.0Responses\", exist_ok=True)\n",
    "\n",
    "# Initialize counter for saving\n",
    "counter = [0]\n",
    "total_rows = len(df_sharegpt)\n",
    "\n",
    "# Define a function to process each row and save every 100 rows\n",
    "def process_and_save(prompt):\n",
    "    response = safe_generate_response(prompt)\n",
    "    counter[0] += 1\n",
    "    \n",
    "    # Save every 100 rows\n",
    "    if counter[0] % 100 == 0:\n",
    "        batch_num = counter[0] // 100\n",
    "        print(f\"Processed {counter[0]} rows. Saving batch {batch_num}...\")\n",
    "        df_sharegpt.to_csv(f\"../data/Flash2.0Responses/responses_batch_{batch_num}.csv\", index=False)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Apply the function to each row in the dataframe with tqdm progress bar\n",
    "tqdm.pandas(desc=\"Processing prompts\")\n",
    "df_sharegpt['base_response'] = df_sharegpt['original_prompt'].progress_apply(process_and_save)\n",
    "\n",
    "# Save the final complete dataset\n",
    "df_sharegpt.to_csv(\"../data/Flash2.0Responses/all_responses.csv\", index=False)\n",
    "print(f\"Completed generating {total_rows} improved prompts\")\n",
    "print(f\"Final results saved to ../data/Flash2.0Responses/all_responses.csv\")\n",
    "\n",
    "print(\"\\nSample of results:\")\n",
    "display(df_sharegpt[['original_prompt', 'base_response']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making requests to the fine-tuned model on Vertex AI...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ExampleStoreServiceClient' from partially initialized module 'google.cloud.aiplatform_v1beta1.services.example_store_service' (most likely due to a circular import) (c:\\Users\\austi\\oneprompted\\.venv\\Lib\\site-packages\\google\\cloud\\aiplatform_v1beta1\\services\\example_store_service\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauth\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m aiplatform\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\austi\\oneprompted\\.venv\\Lib\\site-packages\\google\\cloud\\aiplatform\\__init__.py:24\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version \u001b[38;5;28;01mas\u001b[39;00m aiplatform_version\n\u001b[32m     21\u001b[39m __version__ = aiplatform_version.__version__\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m initializer\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     27\u001b[39m     ImageDataset,\n\u001b[32m     28\u001b[39m     TabularDataset,\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m     VideoDataset,\n\u001b[32m     32\u001b[39m )\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m explain\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\austi\\oneprompted\\.venv\\Lib\\site-packages\\google\\cloud\\aiplatform\\initializer.py:35\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauth\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GoogleAuthError\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m base \u001b[38;5;28;01mas\u001b[39;00m constants\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\austi\\oneprompted\\.venv\\Lib\\site-packages\\google\\cloud\\aiplatform\\compat\\__init__.py:18\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Copyright 2023 Google LLC\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m services\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types\n\u001b[32m     21\u001b[39m V1BETA1 = \u001b[33m\"\u001b[39m\u001b[33mv1beta1\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\austi\\oneprompted\\.venv\\Lib\\site-packages\\google\\cloud\\aiplatform\\compat\\services\\__init__.py:27\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform_v1beta1\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeployment_resource_pool_service\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     client \u001b[38;5;28;01mas\u001b[39;00m deployment_resource_pool_service_client_v1beta1,\n\u001b[32m     23\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform_v1beta1\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mendpoint_service\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     client \u001b[38;5;28;01mas\u001b[39;00m endpoint_service_client_v1beta1,\n\u001b[32m     26\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform_v1beta1\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexample_store_service\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     28\u001b[39m     client \u001b[38;5;28;01mas\u001b[39;00m example_store_service_client_v1beta1,\n\u001b[32m     29\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform_v1beta1\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension_execution_service\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     31\u001b[39m     client \u001b[38;5;28;01mas\u001b[39;00m extension_execution_service_client_v1beta1,\n\u001b[32m     32\u001b[39m )\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform_v1beta1\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension_registry_service\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     34\u001b[39m     client \u001b[38;5;28;01mas\u001b[39;00m extension_registry_service_client_v1beta1,\n\u001b[32m     35\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\austi\\oneprompted\\.venv\\Lib\\site-packages\\google\\cloud\\aiplatform_v1beta1\\services\\example_store_service\\__init__.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Copyright 2025 Google LLC\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExampleStoreServiceClient\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01masync_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExampleStoreServiceAsyncClient\n\u001b[32m     19\u001b[39m __all__ = (\n\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mExampleStoreServiceClient\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mExampleStoreServiceAsyncClient\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\austi\\oneprompted\\.venv\\Lib\\site-packages\\google\\cloud\\aiplatform_v1beta1\\services\\example_store_service\\client.py:37\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     23\u001b[39m     Dict,\n\u001b[32m     24\u001b[39m     Callable,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     cast,\n\u001b[32m     34\u001b[39m )\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maiplatform_v1beta1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gapic_version \u001b[38;5;28;01mas\u001b[39;00m package_version\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m client_options \u001b[38;5;28;01mas\u001b[39;00m client_options_lib\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m exceptions \u001b[38;5;28;01mas\u001b[39;00m core_exceptions\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\austi\\oneprompted\\.venv\\Lib\\site-packages\\google\\cloud\\aiplatform_v1beta1\\__init__.py:33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation_service\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EvaluationServiceClient\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation_service\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EvaluationServiceAsyncClient\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexample_store_service\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExampleStoreServiceClient\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexample_store_service\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExampleStoreServiceAsyncClient\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension_execution_service\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExtensionExecutionServiceClient\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'ExampleStoreServiceClient' from partially initialized module 'google.cloud.aiplatform_v1beta1.services.example_store_service' (most likely due to a circular import) (c:\\Users\\austi\\oneprompted\\.venv\\Lib\\site-packages\\google\\cloud\\aiplatform_v1beta1\\services\\example_store_service\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Check if 'base_response' column exists before dropping it\n",
    "if 'base_response' in df_sharegpt.columns:\n",
    "    df_sharegpt.drop(columns=['base_response'], inplace=True)\n",
    "# Make a request to the fine-tuned model on Vertex AI\n",
    "print(\"Making requests to the fine-tuned model on Vertex AI...\")\n",
    "\n",
    "# Import necessary libraries\n",
    "import google.auth\n",
    "from google.cloud import aiplatform\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Initialize Vertex AI\n",
    "try:\n",
    "    # Initialize Google Cloud credentials\n",
    "    credentials, project_id = google.auth.default()\n",
    "    \n",
    "    # Initialize Vertex AI with the project and region\n",
    "    aiplatform.init(\n",
    "        project=\"astute-asset-456404-r9\",  # Using the project ID from the URL\n",
    "        location=\"us-east1\",  # Using the region from the URL\n",
    "    )\n",
    "    \n",
    "    print(\"Successfully connected to Vertex AI\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Vertex AI: {str(e)}\")\n",
    "\n",
    "# Define function to make request to the fine-tuned model\n",
    "def query_fine_tuned_model(prompt, endpoint_id=\"4533202878436737024\"):\n",
    "    \"\"\"\n",
    "    Send a request to the fine-tuned model endpoint\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get endpoint\n",
    "        endpoint = aiplatform.Endpoint(endpoint_id)\n",
    "        \n",
    "        # Prepare the request payload\n",
    "        request_data = {\n",
    "            \"instances\": [\n",
    "                {\"prompt\": prompt}\n",
    "            ],\n",
    "            \"parameters\": {\n",
    "                \"temperature\": 0.2,\n",
    "                \"maxOutputTokens\": 1024,\n",
    "                \"topK\": 40,\n",
    "                \"topP\": 0.9\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Make prediction\n",
    "        response = endpoint.predict(instances=request_data[\"instances\"], parameters=request_data[\"parameters\"])\n",
    "        \n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Process prompts with the fine-tuned model\n",
    "print(\"Processing prompts with the fine-tuned model...\")\n",
    "\n",
    "# Initialize results list\n",
    "fine_tuned_responses = []\n",
    "\n",
    "# Process in batches to avoid rate limiting\n",
    "batch_size = 10\n",
    "for i in tqdm(range(0, len(df_sharegpt), batch_size), desc=\"Processing with fine-tuned model\"):\n",
    "    batch = df_sharegpt.iloc[i:i+batch_size]\n",
    "    \n",
    "    batch_results = []\n",
    "    for _, row in batch.iterrows():\n",
    "        result = query_fine_tuned_model(row['original_prompt'])\n",
    "        batch_results.append(result)\n",
    "        # Add a small delay to avoid rate limiting\n",
    "        time.sleep(1)\n",
    "    \n",
    "    fine_tuned_responses.extend(batch_results)\n",
    "    \n",
    "    # Save intermediate results\n",
    "    if (i + batch_size) % 100 == 0 or (i + batch_size) >= len(df_sharegpt):\n",
    "        df_sharegpt_ft = df_sharegpt.iloc[:i+len(batch)].copy()\n",
    "        df_sharegpt_ft['fine_tuned_response'] = fine_tuned_responses\n",
    "        df_sharegpt_ft.to_csv(f\"../data/FineTunedResponses/fine_tuned_responses_{i+len(batch)}.csv\", index=False)\n",
    "        print(f\"Saved fine-tuned model responses for {i+len(batch)} prompts\")\n",
    "\n",
    "# Add fine-tuned responses to dataframe\n",
    "df_sharegpt['fine_tuned_response'] = fine_tuned_responses\n",
    "\n",
    "# Save final results\n",
    "df_sharegpt.to_csv(\"../data/FineTunedResponses/fine_tuned_responses.csv\", index=False)\n",
    "\n",
    "print(\"Processing complete. Results saved to ../data/FineTunedResponses/fine_tuned_responses.csv\")\n",
    "\n",
    "# Display sample of results\n",
    "print(\"\\nSample of fine-tuned model results:\")\n",
    "display(df_sharegpt[['original_prompt', 'base_response', 'fine_tuned_response']].head(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import jwt  # pip install pyjwt\n",
    "import requests\n",
    "\n",
    "# === CONFIG ===\n",
    "SERVICE_ACCOUNT_FILE = \"../env.json\"\n",
    "PROJECT_ID = \"astute-asset-456404-r9\"\n",
    "REGION = \"us-east1\"\n",
    "ENDPOINT_ID = \"4533202878436737024\"\n",
    "API_URL = f\"https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{REGION}/endpoints/{ENDPOINT_ID}:predict\"\n",
    "\n",
    "# === STEP 1: Load Service Account and Get Token ===\n",
    "with open(SERVICE_ACCOUNT_FILE, \"r\") as f:\n",
    "    sa = json.load(f)\n",
    "\n",
    "issued_at = int(time.time())\n",
    "expiration_time = issued_at + 3600\n",
    "\n",
    "# Create JWT and get token from Google\n",
    "payload = {\n",
    "    \"iss\": sa[\"client_email\"],\n",
    "    \"scope\": \"https://www.googleapis.com/auth/cloud-platform\",\n",
    "    \"aud\": sa[\"token_uri\"],\n",
    "    \"exp\": expiration_time,\n",
    "    \"iat\": issued_at\n",
    "}\n",
    "signed_jwt = jwt.encode(payload, sa[\"private_key\"], algorithm=\"RS256\")\n",
    "\n",
    "token_response = requests.post(sa[\"token_uri\"], data={\n",
    "    \"grant_type\": \"urn:ietf:params:oauth:grant-type:jwt-bearer\",\n",
    "    \"assertion\": signed_jwt\n",
    "})\n",
    "access_token = token_response.json()[\"access_token\"]\n",
    "\n",
    "# === STEP 2: Prepare the Payload (depends on your model's expected format) ===\n",
    "prompt = \"How can I be a better team leader?\"\n",
    "\n",
    "# This format can vary depending on how you trained the model\n",
    "# If your model expects a simple string input, it could look like this:\n",
    "payload = {\n",
    "    \"instances\": [\n",
    "        {\"prompt\": prompt}\n",
    "    ]\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# === STEP 3: Send the Request ===\n",
    "response = requests.post(API_URL, headers=headers, json=payload)\n",
    "\n",
    "# === STEP 4: Print the Result ===\n",
    "if response.ok:\n",
    "    result = response.json()\n",
    "    print(\"Output:\", result[\"predictions\"][0])\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
