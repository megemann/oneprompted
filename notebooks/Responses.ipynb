{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "from IPython.display import HTML, Markdown, display\n",
    "from google.api_core import retry\n",
    "import os\n",
    "# Import environment variables from env.json\n",
    "import json\n",
    "\n",
    "# Load environment variables from env.json\n",
    "with open('../env.json', 'r') as f:\n",
    "    env_vars = json.load(f)\n",
    "# Set environment variables from the loaded file\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = env_vars[\"google_cloud_project\"]\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = env_vars[\"google_cloud_location\"]\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = env_vars[\"google_genai_use_vertexai\"]\n",
    "# Set the fine-tuned model ID as an environment variable\n",
    "os.environ[\"FINE_TUNED_MODEL_ID\"] = env_vars[\"fine_tuned_v1_model_id\"]\n",
    "os.environ[\"GOOGLE_API_KEY\"] = env_vars[\"google_api_keys\"][0]\n",
    "GOOGLE_API_KEY = os.environ[\"GOOGLE_API_KEY\"]\n",
    "\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "genai.models.Models.generate_content = retry.Retry(\n",
    "    predicate=is_retriable)(genai.models.Models.generate_content)\n",
    "\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/veo-2.0-generate-001\n",
      "models/gemini-2.0-flash-live-001\n",
      "Being a better team leader is a journey, not a destination. It requires continuous learning and adaptation. Here's a breakdown of key areas to focus on, with actionable steps you can take:\n",
      "\n",
      "**I. Core Leadership Principles:**\n",
      "\n",
      "*   **Lead by Example:**\n",
      "    *   **Action:** Model the behavior you expect from your team. Be punctual, organized, committed, and maintain a positive attitude. If you expect them to work hard, you should be seen working hard.\n",
      "    *   **Benefits:** Builds trust, respect, and motivates the team to follow your lead.\n",
      "*   **Set Clear Expectations:**\n",
      "    *   **Action:** Define goals, roles, responsibilities, and deadlines. Clearly communicate them, both verbally and in writing (e.g., in project plans, job descriptions).\n",
      "    *   **Benefits:** Reduces confusion, improves performance, and helps everyone understand what success looks like.\n",
      "*   **Communicate Effectively:**\n",
      "    *   **Action:**\n",
      "        *   **Listen actively:** Pay attention to your team's concerns, ideas, and feedback. Ask clarifying questions.\n",
      "        *   **Be transparent:** Share relevant information, even if it's difficult.\n",
      "        *   **Choose the right communication channel:** Use email for formal announcements, instant messaging for quick updates, and face-to-face meetings for important discussions.\n",
      "        *   **Provide regular updates:** Keep the team informed about progress, roadblocks, and changes.\n",
      "    *   **Benefits:** Prevents misunderstandings, fosters trust, and keeps everyone aligned.\n",
      "*   **Make Decisions:**\n",
      "    *   **Action:** Be decisive, even when faced with difficult choices. Gather information, weigh options, and explain the rationale behind your decisions. Be willing to own up to your mistakes and learn from them.\n",
      "    *   **Benefits:** Provides direction, reduces uncertainty, and moves the team forward.\n",
      "*   **Empower Your Team:**\n",
      "    *   **Action:**\n",
      "        *   **Delegate effectively:** Assign tasks to team members based on their skills and interests, and provide them with the authority and resources they need.\n",
      "        *   **Encourage autonomy:** Give team members the freedom to make decisions within their roles.\n",
      "        *   **Provide support and resources:** Make sure your team has the tools, training, and information they need to succeed.\n",
      "    *   **Benefits:** Increases job satisfaction, boosts productivity, and develops your team's skills.\n",
      "*   **Build Trust and Respect:**\n",
      "    *   **Action:**\n",
      "        *   **Be honest and trustworthy:** Keep your promises and be transparent in your dealings.\n",
      "        *   **Treat everyone with respect:** Value their opinions, listen to their concerns, and avoid favoritism.\n",
      "        *   **Acknowledge and appreciate contributions:** Recognize and reward individual and team accomplishments.\n",
      "    *   **Benefits:** Creates a positive and collaborative work environment, improves morale, and strengthens relationships.\n",
      "*   **Foster a Positive Team Environment:**\n",
      "    *   **Action:**\n",
      "        *   **Encourage open communication and collaboration:** Create a safe space where team members feel comfortable sharing ideas and feedback.\n",
      "        *   **Promote a sense of belonging:** Build camaraderie through team-building activities and social events.\n",
      "        *   **Address conflict constructively:** Mediate disagreements, encourage compromise, and focus on finding solutions.\n",
      "    *   **Benefits:** Improves morale, enhances teamwork, and creates a more enjoyable work experience.\n",
      "\n",
      "**II. Essential Skills to Develop:**\n",
      "\n",
      "*   **Emotional Intelligence (EQ):**\n",
      "    *   **Action:**\n",
      "        *   **Self-awareness:** Understand your own emotions and how they impact others.\n",
      "        *   **Self-regulation:** Manage your emotions, remain calm under pressure, and adapt to changing situations.\n",
      "        *   **Social awareness:** Understand the emotions of others and build rapport.\n",
      "        *   **Relationship management:** Build and maintain strong relationships, manage conflict effectively, and influence others.\n",
      "    *   **How to Improve:** Take an EQ assessment, practice mindfulness, seek feedback, and learn active listening skills.\n",
      "*   **Strategic Thinking:**\n",
      "    *   **Action:** Understand the bigger picture, anticipate future challenges and opportunities, and develop a vision for the team's success.\n",
      "    *   **How to Improve:** Stay informed about industry trends, participate in strategic planning sessions, and practice problem-solving.\n",
      "*   **Problem-Solving and Decision-Making:**\n",
      "    *   **Action:** Develop a structured approach to problem-solving, gather relevant information, analyze options, and make informed decisions.\n",
      "    *   **How to Improve:** Practice using decision-making frameworks (e.g., SWOT analysis, cost-benefit analysis), and learn from past mistakes.\n",
      "*   **Conflict Resolution:**\n",
      "    *   **Action:** Learn how to identify and address conflicts constructively, facilitate communication, and find mutually agreeable solutions.\n",
      "    *   **How to Improve:** Take a conflict resolution course, practice active listening, and learn mediation techniques.\n",
      "*   **Delegation:**\n",
      "    *   **Action:** Learn to assess your team's skills and match them with appropriate tasks. Clearly communicate expectations, provide support, and follow up on progress.\n",
      "    *   **How to Improve:** Practice delegating small tasks at first, and gradually increase the complexity of the assignments you delegate.\n",
      "*   **Giving and Receiving Feedback:**\n",
      "    *   **Action:**\n",
      "        *   **Give feedback:** Be specific, constructive, and focus on behavior rather than personality. Deliver feedback promptly.\n",
      "        *   **Receive feedback:** Listen actively, ask clarifying questions, and be open to learning.\n",
      "    *   **How to Improve:** Practice giving and receiving feedback using the \"SBI\" (Situation, Behavior, Impact) model.\n",
      "\n",
      "**III. Continuous Learning and Improvement:**\n",
      "\n",
      "*   **Seek Feedback:**\n",
      "    *   **Action:** Regularly ask your team members, peers, and superiors for feedback on your leadership style.\n",
      "    *   **Benefits:** Helps you identify areas for improvement and gain valuable insights into your strengths and weaknesses.\n",
      "*   **Read and Learn:**\n",
      "    *   **Action:** Read books, articles, and blogs on leadership and management. Stay informed about the latest trends and best practices.\n",
      "    *   **Benefits:** Expands your knowledge and exposes you to new ideas and perspectives.\n",
      "*   **Attend Training and Workshops:**\n",
      "    *   **Action:** Participate in leadership development programs, workshops, and seminars to hone your skills and learn from experts.\n",
      "    *   **Benefits:** Provides structured learning opportunities and allows you to network with other leaders.\n",
      "*   **Reflect and Adapt:**\n",
      "    *   **Action:** Regularly reflect on your leadership performance and identify areas where you can improve. Be willing to adapt your approach based on the needs of your team and the changing circumstances.\n",
      "    *   **Benefits:** Fosters continuous improvement and helps you become a more effective leader over time.\n",
      "\n",
      "**IV. Practical Steps to Take Immediately:**\n",
      "\n",
      "1.  **Self-Assessment:** Take a moment to honestly assess your leadership strengths and weaknesses. What are you good at? What areas need improvement?\n",
      "2.  **Team Check-In:** Have individual conversations with each of your team members to ask for their feedback. Ask questions like: \"What can I do to support you better?\" or \"What's one thing I could start doing, or stop doing, to be a better leader?\"\n",
      "3.  **Set a SMART Goal:** Choose one specific area where you want to improve and set a SMART goal (Specific, Measurable, Achievable, Relevant, Time-bound). For example: \"By the end of next month, I will hold weekly 1:1 meetings with each team member to provide feedback and check on their progress.\"\n",
      "4.  **Practice Active Listening:** Make a conscious effort to listen more attentively in meetings and conversations. Put away distractions, make eye contact, and ask clarifying questions.\n",
      "5.  **Start Small:** Don't try to change everything at once. Focus on implementing one or two new leadership behaviors at a time.\n",
      "\n",
      "By consistently working on these areas, you can develop the skills and qualities needed to be a more effective team leader, build a high-performing team, and achieve greater success. Remember that it is a continuous journey of improvement.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# List available models\n",
    "print(\"Available models:\")\n",
    "for m in genai.list_models():\n",
    "    print(m.name)\n",
    "\n",
    "# Use a specific model\n",
    "model = genai.GenerativeModel('gemini-2.0-flash-lite-001')  # base untuned model\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(\"How can I be a better team leader?\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you're talking to a 7-year-old. Explain what Artificial Intelligence (AI) is, using simple words and examples they can easily understand. Focus on how AI helps computers do smart things, like playing games or recognizing pictures. Break down the explanation into three short paragraphs. In the first paragraph, define AI in a general way. In the second, give an example of AI in action. In the third, explain a simple limitation of AI. End your response with a single sentence summarizing what AI can do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The genai module doesn't have a Client attribute, so we'll use the GenerativeModel directly\n",
    "# No need to create a client instance\n",
    "\n",
    "def generate_response(prompt):\n",
    "    inputs = f'''You are a prompt engineering expert that transforms simple \n",
    "    prompts into more effective versions. Analyze the input prompt and create\n",
    "      an improved version that includes specific details, context, desired output format, \n",
    "      and any relevant constraints. Make the prompt clear, specific, and designed to \n",
    "      generate high-quality responses.\n",
    "      \n",
    "      Input Prompt: {prompt}\n",
    "\n",
    "      Respond ONLY with the text of the improved prompt, without any explanations, \n",
    "      introductions, or additional commentary.\n",
    "      '''\n",
    "\n",
    "    response = model.generate_content(contents=inputs)\n",
    "    return response.text\n",
    "\n",
    "print(generate_response('Explain AI to me like im a little kid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully with 962 rows\n",
      "\n",
      "Dataset columns:\n",
      "- original_prompt\n",
      "- context\n",
      "- instruction\n",
      "- has_context\n",
      "- conversation_id\n",
      "\n",
      "First 5 rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_prompt</th>\n",
       "      <th>context</th>\n",
       "      <th>instruction</th>\n",
       "      <th>has_context</th>\n",
       "      <th>conversation_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One-pot vegetarian pasta recipes for busy nights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One-pot vegetarian pasta recipes for busy nights</td>\n",
       "      <td>False</td>\n",
       "      <td>93453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We have the following blog content... what is ...</td>\n",
       "      <td>The content:\\n\\nConsumers want more choices, b...</td>\n",
       "      <td>We have the following blog content... what is ...</td>\n",
       "      <td>True</td>\n",
       "      <td>65263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how o sort element using merge sort technique ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>how o sort element using merge sort technique ...</td>\n",
       "      <td>False</td>\n",
       "      <td>99000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make a javascript class \"GraphicLayer\" which i...</td>\n",
       "      <td>One of those properties will be center point, ...</td>\n",
       "      <td>make a javascript class \"GraphicLayer\" which i...</td>\n",
       "      <td>True</td>\n",
       "      <td>96296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please outline the steps to build an automated...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Please outline the steps to build an automated...</td>\n",
       "      <td>False</td>\n",
       "      <td>38806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     original_prompt  \\\n",
       "0   One-pot vegetarian pasta recipes for busy nights   \n",
       "1  We have the following blog content... what is ...   \n",
       "2  how o sort element using merge sort technique ...   \n",
       "3  make a javascript class \"GraphicLayer\" which i...   \n",
       "4  Please outline the steps to build an automated...   \n",
       "\n",
       "                                             context  \\\n",
       "0                                                NaN   \n",
       "1  The content:\\n\\nConsumers want more choices, b...   \n",
       "2                                                NaN   \n",
       "3  One of those properties will be center point, ...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         instruction  has_context  \\\n",
       "0   One-pot vegetarian pasta recipes for busy nights        False   \n",
       "1  We have the following blog content... what is ...         True   \n",
       "2  how o sort element using merge sort technique ...        False   \n",
       "3  make a javascript class \"GraphicLayer\" which i...         True   \n",
       "4  Please outline the steps to build an automated...        False   \n",
       "\n",
       "   conversation_id  \n",
       "0            93453  \n",
       "1            65263  \n",
       "2            99000  \n",
       "3            96296  \n",
       "4            38806  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the ShareGPT dataset from CSV\n",
    "try:\n",
    "    # Define the path to the CSV file\n",
    "    csv_path = \"../data/Prompt_Training_2.0/seperated_test_data.csv\"\n",
    "    \n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df_sharegpt = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Display basic information about the dataset\n",
    "    print(f\"Dataset loaded successfully with {len(df_sharegpt)} rows\")\n",
    "    print(\"\\nDataset columns:\")\n",
    "    for col in df_sharegpt.columns:\n",
    "        print(f\"- {col}\")\n",
    "    \n",
    "    # Display the first few rows of the dataset\n",
    "    print(\"\\nFirst 5 rows of the dataset:\")\n",
    "    display(df_sharegpt.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file at '../data/Prompt_Training_2.0/seperated_test_data.csv' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the dataset: {str(e)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating improved prompts for each original prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts: 100%|██████████| 962/962 [37:52<00:00,  2.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed generating 962 improved prompts\n",
      "Final results saved to ../data/BaseModelResponses/improved_prompts.csv\n",
      "\n",
      "Sample of results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_prompt</th>\n",
       "      <th>base_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One-pot vegetarian pasta recipes for busy nights</td>\n",
       "      <td>Create a list of five (5) unique one-pot veget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We have the following blog content... what is ...</td>\n",
       "      <td>Analyze the provided blog content about choosi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how o sort element using merge sort technique ...</td>\n",
       "      <td>Write a Java program that implements the Merge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     original_prompt  \\\n",
       "0   One-pot vegetarian pasta recipes for busy nights   \n",
       "1  We have the following blog content... what is ...   \n",
       "2  how o sort element using merge sort technique ...   \n",
       "\n",
       "                                       base_response  \n",
       "0  Create a list of five (5) unique one-pot veget...  \n",
       "1  Analyze the provided blog content about choosi...  \n",
       "2  Write a Java program that implements the Merge...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the generate_response function to each original_prompt in the dataframe\n",
    "# This will create a new column 'base_response' with the improved prompts\n",
    "print(\"Generating improved prompts for each original prompt...\")\n",
    "\n",
    "# Import tqdm for progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define a function to safely apply generate_response\n",
    "def safe_generate_response(prompt):\n",
    "    try:\n",
    "        return generate_response(prompt)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing prompt: {str(e)[:100]}...\")\n",
    "        return \"Error generating response\"\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(\"../data/BaseModelResponses\", exist_ok=True)\n",
    "\n",
    "# Initialize counter for saving\n",
    "counter = [0]\n",
    "total_rows = len(df_sharegpt)\n",
    "\n",
    "# Define a function to process each row and save every 100 rows\n",
    "def process_and_save(prompt):\n",
    "    response = safe_generate_response(prompt)\n",
    "    return response\n",
    "\n",
    "# Apply the function to each row in the dataframe with tqdm progress bar\n",
    "tqdm.pandas(desc=\"Processing prompts\")\n",
    "df_sharegpt['base_response'] = df_sharegpt['original_prompt'].progress_apply(process_and_save)\n",
    "\n",
    "# Save the final complete dataset\n",
    "df_sharegpt.to_csv(\"../data/BaseModelResponses/improved_prompts.csv\", index=False)\n",
    "print(f\"Completed generating {total_rows} improved prompts\")\n",
    "print(f\"Final results saved to ../data/BaseModelResponses/improved_prompts.csv\")\n",
    "\n",
    "print(\"\\nSample of results:\")\n",
    "display(df_sharegpt[['original_prompt', 'base_response']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a seasoned leadership consultant. Provide a comprehensive guide on how to improve team leadership skills. Break down the guide into the following sections:\n",
      "\n",
      "1.  **Understanding the Fundamentals:** Define team leadership, discuss its importance, and outline the core responsibilities of a team leader.\n",
      "2.  **Building Effective Communication:** Detail strategies for clear, concise, and empathetic communication within a team. Include tips on active listening, providing constructive feedback, and handling difficult conversations.\n",
      "3.  **Motivating and Engaging Team Members:** Explain different motivational techniques, such as recognition, rewards, and opportunities for growth. Discuss how to create a positive and engaging work environment.\n",
      "4.  **Delegation and Empowerment:** Describe how to delegate tasks effectively and empower team members to take ownership and responsibility. Include strategies for monitoring progress and providing support.\n",
      "5.  **Conflict Resolution:** Outline steps for resolving conflicts within a team in a constructive and productive manner. Discuss techniques for mediation and compromise.\n",
      "\n",
      "For each section, provide actionable advice and examples. Use CONTEXTUAL_PROMPTING to tailor the advice to a hypothetical team of software engineers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google import genai\n",
    "from google.genai.types import HttpOptions\n",
    "\n",
    "\n",
    "\n",
    "# Access the model ID from environment variables\n",
    "fine_tuned_model_id = os.environ[\"FINE_TUNED_MODEL_ID\"]\n",
    "\n",
    "\n",
    "# Initialize the GenAI client for Vertex AI\n",
    "client = genai.Client(http_options=HttpOptions(api_version=\"v1\"))\n",
    "\n",
    "# Define your prompt\n",
    "prompt = \"How can I be a better team leader?\"\n",
    "\n",
    "# Call your fine-tuned model\n",
    "response = client.models.generate_content(\n",
    "    model=fine_tuned_model_id,\n",
    "    contents=prompt,\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works with no context, but you can do with context too\n",
    "def generate_response(prompt):\n",
    "    inputs = f'''You are a prompt engineering expert that transforms simple \n",
    "    prompts into more effective versions. Analyze the input prompt and create\n",
    "      an improved version that includes specific details, context, desired output format, \n",
    "      and any relevant constraints. Make the prompt clear, specific, and designed to \n",
    "      generate high-quality responses.\n",
    "      \n",
    "      Input Prompt: {prompt}\n",
    "\n",
    "      Respond ONLY with the text of the improved prompt, without any explanations, \n",
    "      introductions, or additional commentary.\n",
    "      '''\n",
    "\n",
    "    return client.models.generate_content(\n",
    "        model=fine_tuned_model_id,\n",
    "        contents=inputs).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully with 962 rows\n",
      "\n",
      "Dataset columns:\n",
      "- original_prompt\n",
      "- context\n",
      "- instruction\n",
      "- has_context\n",
      "- conversation_id\n",
      "\n",
      "First 5 rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_prompt</th>\n",
       "      <th>context</th>\n",
       "      <th>instruction</th>\n",
       "      <th>has_context</th>\n",
       "      <th>conversation_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One-pot vegetarian pasta recipes for busy nights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One-pot vegetarian pasta recipes for busy nights</td>\n",
       "      <td>False</td>\n",
       "      <td>93453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We have the following blog content... what is ...</td>\n",
       "      <td>The content:\\n\\nConsumers want more choices, b...</td>\n",
       "      <td>We have the following blog content... what is ...</td>\n",
       "      <td>True</td>\n",
       "      <td>65263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how o sort element using merge sort technique ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>how o sort element using merge sort technique ...</td>\n",
       "      <td>False</td>\n",
       "      <td>99000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make a javascript class \"GraphicLayer\" which i...</td>\n",
       "      <td>One of those properties will be center point, ...</td>\n",
       "      <td>make a javascript class \"GraphicLayer\" which i...</td>\n",
       "      <td>True</td>\n",
       "      <td>96296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please outline the steps to build an automated...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Please outline the steps to build an automated...</td>\n",
       "      <td>False</td>\n",
       "      <td>38806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     original_prompt  \\\n",
       "0   One-pot vegetarian pasta recipes for busy nights   \n",
       "1  We have the following blog content... what is ...   \n",
       "2  how o sort element using merge sort technique ...   \n",
       "3  make a javascript class \"GraphicLayer\" which i...   \n",
       "4  Please outline the steps to build an automated...   \n",
       "\n",
       "                                             context  \\\n",
       "0                                                NaN   \n",
       "1  The content:\\n\\nConsumers want more choices, b...   \n",
       "2                                                NaN   \n",
       "3  One of those properties will be center point, ...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         instruction  has_context  \\\n",
       "0   One-pot vegetarian pasta recipes for busy nights        False   \n",
       "1  We have the following blog content... what is ...         True   \n",
       "2  how o sort element using merge sort technique ...        False   \n",
       "3  make a javascript class \"GraphicLayer\" which i...         True   \n",
       "4  Please outline the steps to build an automated...        False   \n",
       "\n",
       "   conversation_id  \n",
       "0            93453  \n",
       "1            65263  \n",
       "2            99000  \n",
       "3            96296  \n",
       "4            38806  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the ShareGPT dataset from CSV\n",
    "try:\n",
    "    # Define the path to the CSV file\n",
    "    csv_path = \"../data/Prompt_Training_2.0/seperated_test_data.csv\"\n",
    "    \n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df_sharegpt = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Display basic information about the dataset\n",
    "    print(f\"Dataset loaded successfully with {len(df_sharegpt)} rows\")\n",
    "    print(\"\\nDataset columns:\")\n",
    "    for col in df_sharegpt.columns:\n",
    "        print(f\"- {col}\")\n",
    "    \n",
    "    # Display the first few rows of the dataset\n",
    "    print(\"\\nFirst 5 rows of the dataset:\")\n",
    "    display(df_sharegpt.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file at '../data/Prompt_Training_2.0/seperated_test_data.csv' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the dataset: {str(e)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating improved prompts for each original prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts: 100%|██████████| 962/962 [26:43<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed generating 962 improved prompts\n",
      "Final results saved to ../data/FineTunedResponses/all_responses.csv\n",
      "\n",
      "Sample of results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_prompt</th>\n",
       "      <th>fine_tuned_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One-pot vegetarian pasta recipes for busy nights</td>\n",
       "      <td>I am looking for one-pot vegetarian pasta reci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We have the following blog content... what is ...</td>\n",
       "      <td>Here's an example of how to analyze blog conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how o sort element using merge sort technique ...</td>\n",
       "      <td>I need a Java function implementation for the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     original_prompt  \\\n",
       "0   One-pot vegetarian pasta recipes for busy nights   \n",
       "1  We have the following blog content... what is ...   \n",
       "2  how o sort element using merge sort technique ...   \n",
       "\n",
       "                                 fine_tuned_response  \n",
       "0  I am looking for one-pot vegetarian pasta reci...  \n",
       "1  Here's an example of how to analyze blog conte...  \n",
       "2  I need a Java function implementation for the ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the generate_response function to each original_prompt in the dataframe\n",
    "# This will create a new column 'base_response' with the improved prompts\n",
    "print(\"Generating improved prompts for each original prompt...\")\n",
    "\n",
    "# Import tqdm for progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define a function to safely apply generate_response\n",
    "def safe_generate_response(prompt):\n",
    "    try:\n",
    "        return generate_response(prompt)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing prompt: {str(e)[:100]}...\")\n",
    "        return \"Error generating response\"\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(\"../data/FineTunedResponses\", exist_ok=True)\n",
    "\n",
    "# Initialize counter for saving\n",
    "counter = [0]\n",
    "total_rows = len(df_sharegpt)\n",
    "\n",
    "# Define a function to process each row and save every 100 rows\n",
    "def process_and_save(prompt):\n",
    "    response = safe_generate_response(prompt)\n",
    "    counter[0] += 1\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Apply the function to each row in the dataframe with tqdm progress bar\n",
    "tqdm.pandas(desc=\"Processing prompts\")\n",
    "df_sharegpt['fine_tuned_response'] = df_sharegpt['original_prompt'].progress_apply(process_and_save)\n",
    "\n",
    "# Save the final complete dataset\n",
    "df_sharegpt.to_csv(\"../data/FineTunedResponses/all_responses.csv\", index=False)\n",
    "print(f\"Completed generating {total_rows} improved prompts\")\n",
    "print(f\"Final results saved to ../data/FineTunedResponses/all_responses.csv\")\n",
    "\n",
    "print(\"\\nSample of results:\")\n",
    "display(df_sharegpt[['original_prompt', 'fine_tuned_response']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-pot vegetarian pasta recipes for busy nights\n",
      "Here are a few examples of well-crafted one-pot pasta recipes:\n",
      "\n",
      "Example 1: One-Pot Creamy Tomato Pasta\n",
      "Ingredients: 1 pound pasta, 1 can diced tomatoes, 1 cup vegetable broth, 1/2 cup heavy cream, 1/4 cup chopped basil, salt, pepper\n",
      "Instructions: In a large pot, combine pasta, tomatoes, and broth. Bring to a boil and cook until pasta is al dente. Stir in heavy cream, basil, salt, and pepper. Simmer for a few minutes to thicken.\n",
      "\n",
      "Example 2: One-Pot Lemon Garlic Pasta\n",
      "Ingredients: 1 pound pasta, 1/2 cup olive oil, 4 cloves garlic, minced, 1 lemon, zested and juiced, 1 cup vegetable broth, salt, pepper\n",
      "Instructions: Heat olive oil in a large pot. Sauté garlic until fragrant. Add pasta, lemon zest, and juice, and broth. Bring to a boil and cook until pasta is al dente. Season with salt and pepper.\n",
      "\n",
      "Now, create a one-pot pasta recipe with the following ingredients:\n",
      "\n",
      "Ingredients: 1 pound pasta, 1 jar pesto, 1 can cannellini beans, 1 cup vegetable broth, 1/4 cup Parmesan cheese, salt, pepper\n",
      "Instructions:\n"
     ]
    }
   ],
   "source": [
    "print(df_sharegpt['original_prompt'].iloc[0])\n",
    "\n",
    "print(generate_response(df_sharegpt['original_prompt'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random examples of prompts and their fine-tuned responses:\n",
      "\n",
      "--- Example 654 ---\n",
      "Original Prompt:\n",
      "I want you to act as a plagiarism checker. I will write you sentences and you will only reply detected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations in replies. My first sentence is \"\"Quantitative data is any data that is in numerical form such as statistics, percentages, etc. The researcher analyses the data with the help of statistics and hopes the numbers will yield an unbiased result that can be generalized to some larger population.\"\"\n",
      "\n",
      "Fine-tuned Response:\n",
      "I need a Python function called `detect_plagiarism(text)` that checks if a given text is plagiarized. The function should take a string as input and return `True` if plagiarism is detected, and `False` otherwise. Use a plagiarism detection library like `jplag` or `py_stringmatching` to perform the plagiarism check. The function should handle edge cases such as empty input and single-word inputs. Also, the function should return the percent of the text that is plagiarized. Provide the complete code for the function.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Example 114 ---\n",
      "Original Prompt:\n",
      "1 / 1plan a weekend road trip by rented car from IIT bombay to daman including dahanu beach. Provide the full itinerary with all the expected expenses including fooding, lodging etc\n",
      "\n",
      "Fine-tuned Response:\n",
      "Here's an example to guide you:\n",
      "\n",
      "Input Prompt: Consider a scenario where I am planning a weekend getaway from Mumbai to Goa with a budget of INR 15,000. My travel dates are July 14th and 15th. I need to factor in fuel costs, accommodation for two nights (consider options ranging from budget to mid-range), meals, and possible activities. Provide a detailed itinerary including estimated costs for each component, potential lodging suggestions with price ranges, and recommendations for budget-friendly eating options in Goa. Assume the car rental will be approximately INR 4,000 for the entire trip.\n",
      "\n",
      "Output:\n",
      "Itinerary:\n",
      "Day 1: July 14th\n",
      "Morning: Depart from Mumbai to Goa (approx. 10-hour drive)\n",
      "Fuel cost: INR 2,500 (based on average fuel prices and distance)\n",
      "Lunch: Stop at a roadside restaurant for lunch (approx. INR 500)\n",
      "Afternoon: Arrive in Goa, check into hotel\n",
      "Accommodation: [Suggest budget-friendly hotels in Goa (e.g., Palolem Beach Resort, Siolim House)]\n",
      "   Price Range: INR 1,500 - 3,000 per night\n",
      "Evening: Dinner at a local restaurant (approx. INR 800)\n",
      "Day 2: July 15th\n",
      "Morning: Explore beaches (Palolem, Calangute)\n",
      "Activity: [Suggest free/low-cost activities in Goa]\n",
      "Lunch: Enjoy lunch at a beach shack (approx. INR 600)\n",
      "Afternoon: Depart from Goa back to Mumbai\n",
      "Fuel cost: INR 2,500 (based on average fuel prices and distance)\n",
      "Total Estimated Expenses:\n",
      "Fuel: INR 5,000\n",
      "Accommodation (2 nights): INR 3,000 - 6,000\n",
      "Food: INR 1,900\n",
      "Activities: [Provide estimated cost range]\n",
      "Car Rental: INR 4,000\n",
      "Total: INR 14,000 - 16,900\n",
      "\n",
      "Now, provide a detailed itinerary for a weekend road trip by rented car from IIT Bombay to Daman including Dahanu beach, considering factors like fuel costs, lodging, meals, and potential activities. Assume the trip starts on Saturday, July 20th, and ends on Sunday, July 21st. Provide estimated costs for each component and suggest lodging and dining options.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Example 25 ---\n",
      "Original Prompt:\n",
      "Thomas Menzies\n",
      "71 Kelhead Avenue, Glasgow, G52 4AA | 07827675556 | ThomasLMenzies@gmail.com\n",
      "Personal Profile\n",
      "•\tI am a mature, positive and hardworking individual, who always strives to achieve the highest standard possible, at any given task. I possess excellent communication skills, and I can work well as part of a team and also on my own. I enjoy learning new things, I can work very well under pressure and I have the sales experience to handle customer complaints and solving problematic situations. \n",
      "Experience\n",
      "CHARGEHAND| THE GARAGE | JANRUARY 2018 – CURRENT\n",
      "490 Sauchiehall St, Glasgow G2 3LW\n",
      "RESPONSIBILITIES \n",
      "•\tSorting & Signing for Deliveries\n",
      "•\tCounting Stock\n",
      "•\tAssist with training new employees\n",
      "•\tCash Handling\n",
      "•\tAllocating jobs to the Staff on my bar depending on their ability \n",
      "•\tEnsuring that the Bar is setup for any Event/Gig\n",
      "•\tEnsuring the bar is kept to a high level of cleanliness\n",
      "•\tPerforming under high traffic/pressure environments\n",
      "•\tCo-Operating with other Team Leaders, Chargehands, Management and the Security team\n",
      "Skills & Abilities\n",
      "•\tCommunication\n",
      "•\tPOS Systems\n",
      "•\tCustomer Service\n",
      "•\tAbility to Work Under Pressure\n",
      "•\tTime Management\n",
      "•\tLeadership\n",
      "•\tTeamwork\n",
      "•\tFlexible \n",
      "•\tResponsible \n",
      "•\tEfficient \n",
      "\t\n",
      "FRONT COUNTER CASHIER | CAFÉ ASIA | SEP 2017 – CURRENT\n",
      "1357-1359 Barrhead Rd, Barrhead, Glasgow G53 7DA\n",
      "RESPONSIBILITIES \n",
      "•\tManage Walk ins, Online and Telephone orders and Table Bookings\n",
      "•\tTake Orders and Process payment transactions\n",
      "•\tCash Handling\n",
      "•\tKeeping staff busy and productive at all times\n",
      "•\tPerforming under high traffic/pressure environments\n",
      "Skills & Abilities\n",
      "•\tCommunication\n",
      "•\tCustomer Service\n",
      "•\tAbility to Work Under Pressure\n",
      "•\tResponsible \n",
      "•\tEfficient \n",
      "Education\n",
      "ROSSHALL ACADEMY| AUGUST 2011 – JUNE 2017 \n",
      "•\tMathematics – National 4\n",
      "•\tEnglish – National 4\n",
      "•\tDesign and Manufacture – National 4\n",
      "•\tPractical Woodwork – National 5\n",
      "•\tComputer Science – Higher \n",
      "•\tPractical Electronics – National 4\n",
      "CARDONALD COLLEGE | DECEMBER 2017 \n",
      "•\tComputer Hardware: Hardware Installation and Maintenance – SCQF LEVEL 7\n",
      "•\tComputer Systems Fundamentals – SCQF LEVEL 7\n",
      "•\tProfessionalism and Ethics in Computing – SCQF LEVEL 7\n",
      "•\tNetworking Technology – SCQF LEVEL 8\n",
      "•\tMTA: Networking Fundamentals \n",
      "TENNENT’S TRAINING ACADEMY\n",
      "•\tPersonal License\n",
      "\n",
      "References\n",
      "Available on request. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fine-tuned Response:\n",
      "You are an expert resume writer. Please rewrite the following resume to be more professional, concise, and impactful. Focus on highlighting Thomas Menzies's key accomplishments and skills using strong action verbs and quantifiable results where possible. The original resume is as follows:\n",
      "[Insert Original Resume Here]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Example 759 ---\n",
      "Original Prompt:\n",
      "recommend the name of company related with electric charging station\n",
      "\n",
      "Fine-tuned Response:\n",
      "You are a helpful assistant. I need a list of companies involved in the electric vehicle charging station industry. Provide the company name, a brief description of their products or services, and their location. Give the response in a well-formatted JSON array, with each entry having the keys 'name', 'description', and 'location'. Use JSON format.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Example 281 ---\n",
      "Original Prompt:\n",
      "act as an expert android architecture developer \n",
      "\n",
      "Fine-tuned Response:\n",
      "I want you to act as a seasoned Android architecture expert. Your task is to analyze the following architectural design for a mobile application and provide constructive feedback. The application aims to handle user authentication, data storage, and real-time communication. Consider factors like maintainability, scalability, security, and adherence to current best practices. Provide specific suggestions for improvement, including alternative architectural patterns or libraries that could be used. Also, highlight any potential pitfalls or areas of concern. The application's target audience is enterprise-level clients. Please respond with the improved prompt only.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Random examples as a dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_prompt</th>\n",
       "      <th>fine_tuned_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>I want you to act as a plagiarism checker. I w...</td>\n",
       "      <td>I need a Python function called `detect_plagia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1 / 1plan a weekend road trip by rented car fr...</td>\n",
       "      <td>Here's an example to guide you:\\n\\nInput Promp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Thomas Menzies\\n71 Kelhead Avenue, Glasgow, G5...</td>\n",
       "      <td>You are an expert resume writer. Please rewrit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>recommend the name of company related with ele...</td>\n",
       "      <td>You are a helpful assistant. I need a list of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>act as an expert android architecture developer</td>\n",
       "      <td>I want you to act as a seasoned Android archit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_prompt  \\\n",
       "654  I want you to act as a plagiarism checker. I w...   \n",
       "114  1 / 1plan a weekend road trip by rented car fr...   \n",
       "25   Thomas Menzies\\n71 Kelhead Avenue, Glasgow, G5...   \n",
       "759  recommend the name of company related with ele...   \n",
       "281   act as an expert android architecture developer    \n",
       "\n",
       "                                   fine_tuned_response  \n",
       "654  I need a Python function called `detect_plagia...  \n",
       "114  Here's an example to guide you:\\n\\nInput Promp...  \n",
       "25   You are an expert resume writer. Please rewrit...  \n",
       "759  You are a helpful assistant. I need a list of ...  \n",
       "281  I want you to act as a seasoned Android archit...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display random examples from the dataset\n",
    "import random\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Select 5 random indices from the dataframe\n",
    "random_indices = random.sample(range(len(df_sharegpt)), 5)\n",
    "\n",
    "print(\"\\nRandom examples of prompts and their fine-tuned responses:\")\n",
    "for idx in random_indices:\n",
    "    print(f\"\\n--- Example {idx} ---\")\n",
    "    print(f\"Original Prompt:\\n{df_sharegpt['original_prompt'].iloc[idx]}\")\n",
    "    print(f\"\\nFine-tuned Response:\\n{df_sharegpt['fine_tuned_response'].iloc[idx]}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Alternative display using pandas\n",
    "print(\"\\nRandom examples as a dataframe:\")\n",
    "display(df_sharegpt.loc[random_indices, ['original_prompt', 'fine_tuned_response']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned responses\n",
    "print(\"Loading fine-tuned responses...\")\n",
    "df_fine_tuned = pd.read_csv(\"../data/FineTunedResponses/improved_prompts.csv\")\n",
    "\n",
    "# Load the Flash 2.0 responses\n",
    "print(\"Loading Flash 2.0 responses...\")\n",
    "df_flash = pd.read_csv(\"../data/BaseModel/improved_prompts.csv\")\n",
    "\n",
    "# Join the datasets on original_id\n",
    "print(\"Joining datasets on original_id...\")\n",
    "df_combined = pd.merge(\n",
    "    df_fine_tuned, \n",
    "    df_flash,\n",
    "    on=\"original_id\",\n",
    "    suffixes=(\"_fine_tuned\", \"_flash\")\n",
    ")\n",
    "\n",
    "# Display information about the combined dataset\n",
    "print(f\"Combined dataset shape: {df_combined.shape}\")\n",
    "print(\"\\nSample of combined results:\")\n",
    "display(df_combined[['original_id', 'original_prompt_fine_tuned', 'fine_tuned_response', 'base_response']].head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some readable examples from the combined dataset\n",
    "print(\"\\nReadable examples from the combined dataset:\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Select different examples to display in a more readable format\n",
    "# Choose examples with interesting contrasts between fine-tuned and base responses\n",
    "sample_indices = [116016, 132819, 654]  # Different examples from the dataset\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    row_idx = df_combined.index[df_combined['original_id'] == idx][0] if idx in df_combined['original_id'].values else i\n",
    "    print(f\"\\n\\n--- Example {i+1} ---\")\n",
    "    print(f\"Original Prompt:\\n{df_combined['original_prompt_fine_tuned'].iloc[row_idx]}\")\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(f\"Fine-tuned Model Response:\\n{df_combined['fine_tuned_response'].iloc[row_idx]}\")\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(f\"Base Model Response:\\n{df_combined['base_response'].iloc[row_idx]}\")\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "\n",
    "# Get 5 random examples for additional variety\n",
    "random_indices = random.sample(range(len(df_combined)), 5)\n",
    "print(\"\\n\\nAdditional random examples:\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    print(f\"\\n\\n--- Random Example {i+1} ---\")\n",
    "    print(f\"Original Prompt:\\n{df_combined['original_prompt_fine_tuned'].iloc[idx]}\")\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(f\"Fine-tuned Model Response:\\n{df_combined['fine_tuned_response'].iloc[idx]}\")\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(f\"Base Model Response:\\n{df_combined['base_response'].iloc[idx]}\")\n",
    "    print(\"\\n\" + \"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/gemini-2.0-flash-live-001\n",
      "\n",
      "Processing fine-tuned prompts:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 132/962 [16:38<1:58:39,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing prompt 132: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\n",
      "Got a: <class 'float'>\n",
      "Value: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 175/962 [21:28<1:57:37,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing prompt 175: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\n",
      "Got a: <class 'float'>\n",
      "Value: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 421/962 [54:39<57:03,  6.33s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing prompt 421: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\n",
      "Got a: <class 'float'>\n",
      "Value: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 448/962 [58:42<1:28:35, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing prompt 448: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\n",
      "Got a: <class 'float'>\n",
      "Value: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 495/962 [1:04:43<40:21,  5.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing prompt 495: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\n",
      "Got a: <class 'float'>\n",
      "Value: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 554/962 [1:12:22<1:26:46, 12.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing prompt 554: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\n",
      "Got a: <class 'float'>\n",
      "Value: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 638/962 [1:23:11<34:11,  6.33s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing prompt 638: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\n",
      "Got a: <class 'float'>\n",
      "Value: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 756/962 [1:38:09<24:47,  7.22s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing prompt 756: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\n",
      "Got a: <class 'float'>\n",
      "Value: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 773/962 [1:40:24<31:30, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing prompt 773: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\n",
      "Got a: <class 'float'>\n",
      "Value: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 962/962 [2:03:37<00:00,  7.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Responses saved to ../data/FineTunedResponses/responses.csv\n",
      "\n",
      "Sample responses to fine-tuned prompts:\n",
      "                                   fine_tuned_prompt  \\\n",
      "0  I am looking for one-pot vegetarian pasta reci...   \n",
      "1  Here's an example of how to analyze blog conte...   \n",
      "2  I need a Java function implementation for the ...   \n",
      "\n",
      "                                            response  \n",
      "0  Okay, here are three one-pot vegetarian pasta ...  \n",
      "1  Okay, I need the blog content to analyze! Plea...  \n",
      "2  ```java\\n// MergeSort.java\\npublic class Merge...  \n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "def get_response(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "# Rename fine_tuned_response to fine_tuned_prompt in the all_prompts.csv file\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the prompts from the CSV file\n",
    "prompts_df = pd.read_csv(\"../data/FineTunedResponses/improved_prompts.csv\")\n",
    "\n",
    "# Rename the column\n",
    "prompts_df = prompts_df.rename(columns={'fine_tuned_response': 'fine_tuned_prompt'})\n",
    "\n",
    "# Create a new column to store the responses\n",
    "prompts_df['response'] = None\n",
    "\n",
    "# Process each prompt and get a response\n",
    "print(\"\\nProcessing fine-tuned prompts:\")\n",
    "for i in tqdm(range(len(prompts_df))):\n",
    "    try:\n",
    "        # Get the response for the fine-tuned prompt\n",
    "        response = get_response(prompts_df.loc[i, 'fine_tuned_prompt'])\n",
    "        prompts_df.loc[i, 'response'] = response\n",
    "        \n",
    "        # Add a small delay to avoid rate limiting\n",
    "        time.sleep(0.5)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing prompt {i}: {e}\")\n",
    "        prompts_df.loc[i, 'response'] = f\"Error: {str(e)}\"\n",
    "        \n",
    "        # Wait a bit longer if there's an error\n",
    "        time.sleep(2)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "prompts_df.to_csv(\"../data/FineTunedResponses/responses.csv\", index=False)\n",
    "print(\"\\nResponses saved to ../data/FineTunedResponses/responses.csv\")\n",
    "\n",
    "# Display a few examples of the responses\n",
    "print(\"\\nSample responses to fine-tuned prompts:\")\n",
    "print(prompts_df[['fine_tuned_prompt', 'response']].head(3))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing BaseModelResponses prompts:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 531/962 [1:03:39<26:34,  3.70s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing prompt 531: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 775/962 [1:36:23<41:31, 13.32s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing prompt 775: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 962/962 [2:01:34<00:00,  7.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Responses saved to ../data/BaseModelResponses/responses.csv\n",
      "\n",
      "Sample responses to Base Model prompts:\n",
      "                                         base_prompt  \\\n",
      "0  Create a list of five (5) unique one-pot veget...   \n",
      "1  Analyze the provided blog content about choosi...   \n",
      "2  Write a Java program that implements the Merge...   \n",
      "\n",
      "                                            response  \n",
      "0  ***\\n\\n**1. Lemon Garlic Spinach Pasta**\\n\\nTh...  \n",
      "1  Here's a breakdown of the analysis:\\n\\n**1. Pr...  \n",
      "2  ```java\\n// Java program to implement Merge So...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "def get_response(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "# Process the prompts from Flash2.0Responses\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the prompts from the CSV file\n",
    "prompts_df = pd.read_csv(\"../data/BaseModelResponses/improved_prompts.csv\")\n",
    "\n",
    "# Rename the columns to match our expected format\n",
    "prompts_df = prompts_df.rename(columns={'base_response': 'base_prompt'})\n",
    "\n",
    "# Create a new column to store the responses\n",
    "prompts_df['response'] = None\n",
    "\n",
    "# Process each prompt and get a response\n",
    "print(\"\\nProcessing BaseModelResponses prompts:\")\n",
    "for i in tqdm(range(len(prompts_df))):\n",
    "    try:\n",
    "        # Get the response for the base prompt\n",
    "        response = get_response(prompts_df.loc[i, 'base_prompt'])\n",
    "        prompts_df.loc[i, 'response'] = response\n",
    "        \n",
    "        # Add a small delay to avoid rate limiting\n",
    "        time.sleep(0.1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing prompt {i}: {e}\")\n",
    "        prompts_df.loc[i, 'response'] = f\"Error: {str(e)}\"\n",
    "        \n",
    "        # Wait a bit longer if there's an error\n",
    "        time.sleep(2)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "prompts_df.to_csv(\"../data/BaseModelResponses/responses.csv\", index=False)\n",
    "print(\"\\nResponses saved to ../data/BaseModelResponses/responses.csv\")\n",
    "\n",
    "# Display a few examples of the responses\n",
    "print(\"\\nSample responses to Base Model prompts:\")\n",
    "print(prompts_df[['base_prompt', 'response']].head(3))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "def get_response(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "# Process the prompts from ShareGPT\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the prompts from the CSV file\n",
    "prompts_df = pd.read_csv(\"../data/Prompt_Training_2.0/seperated_test_data.csv\")\n",
    "\n",
    "# Create a new column to store the responses\n",
    "prompts_df['response'] = None\n",
    "\n",
    "# Process each prompt and get a response\n",
    "print(\"\\nProcessing ShareGPT prompts:\")\n",
    "for i in tqdm(range(len(prompts_df))):\n",
    "    try:\n",
    "        # Get the response for the prompt\n",
    "        response = get_response(prompts_df.loc[i, 'original_prompt'])\n",
    "        prompts_df.loc[i, 'response'] = response\n",
    "        \n",
    "        # Add a small delay to avoid rate limiting\n",
    "        time.sleep(0.5)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing prompt {i}: {e}\")\n",
    "        prompts_df.loc[i, 'response'] = f\"Error: {str(e)}\"\n",
    "        \n",
    "        # Wait a bit longer if there's an error\n",
    "        time.sleep(2)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "prompts_df.to_csv(\"../data/NoModelResponses/responses.csv\", index=False)\n",
    "print(\"\\nResponses saved to ../data/NoModelResponses/responses.csv\")\n",
    "\n",
    "# Display a few examples of the responses\n",
    "print(\"\\nSample responses to ShareGPT prompts:\")\n",
    "print(prompts_df[['original_prompt', 'response']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
