{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up LLMs\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "from IPython.display import HTML, Markdown, display\n",
    "from google.api_core import retry\n",
    "import os\n",
    "# Import environment variables from env.json\n",
    "import json\n",
    "\n",
    "# Load environment variables from env.json\n",
    "with open('../../env.json', 'r') as f:\n",
    "    env_vars = json.load(f)\n",
    "# Set environment variables from the loaded file\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = env_vars[\"google_cloud_project\"]\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = env_vars[\"google_cloud_location\"]\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = env_vars[\"google_genai_use_vertexai\"]\n",
    "# Set the fine-tuned model ID as an environment variable\n",
    "os.environ[\"GOOGLE_API_KEY\"] = env_vars[\"google_api_keys\"][1]\n",
    "GOOGLE_API_KEY = os.environ[\"GOOGLE_API_KEY\"]\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Use a specific model\n",
    "model = genai.GenerativeModel('models/gemini-2.5-pro-preview-03-25')  # base untuned model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess Data\n",
    "The data we collected was very dirty, as it included human responses. Some examples are:\n",
    "1. Messages with just 'hi'\n",
    "2. Messages with rules violations\n",
    "3. Role prompting with DAN to try and bypass rules violations\n",
    "4. Messages with LLM Response Embedded\n",
    "5. Responses in Other languages (had english code)\n",
    "\n",
    "For V2, we then went through each dataset and did context and instruction seperation.\n",
    "\n",
    "Context: Integral information that the user wants unchanged (Code, Articles, etc.)\n",
    "\n",
    "Instruction: Portion of the prompt instructing the LLM what task to do. Our target for engineering\n",
    "\n",
    "From this, we made Validation, Training, and Testing Seperated prompts\n",
    "\n",
    "## 2. Generate Improved Prompts based on human prompts from Share_GPT Dataset\n",
    "- Uses newest model (2.5 pro preview) for most advanced answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(instruction, context):\n",
    "    if context == \"\" or context == None:\n",
    "        context = \"No context provided\" \n",
    "    prompt = f'''\n",
    "    You are a prompt engineering expert.\n",
    "\n",
    "    Your task is to rewrite the instruction below using advanced prompt engineering techniques. If context is provided, use it as *background knowledge* to better understand the task — but do not include it in the final output.\n",
    "\n",
    "    Guidelines:\n",
    "    - Enhance the instruction to be clearer, more specific, and more effective\n",
    "    - Use any prompting technique that best fits\n",
    "    - Ground your rewrite in the provided context, if applicable\n",
    "    - Do NOT copy or reference the context in your rewritten instruction\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Original Instruction:\n",
    "    {instruction}\n",
    "\n",
    "    Output ONLY the improved instruction without any additional text, titling, explanations, or acknowledgment.\n",
    "    '''\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load the validation data\n",
    "validation_data_path = \"../../data/Prompt_Training_2.0/seperated_validation_data.csv\"\n",
    "output_path = \"../../data/Prompt_Training_2.0/labeled_validation_data.csv\"\n",
    "\n",
    "# Load the validation data\n",
    "testing_data_path = \"../../data/Prompt_Training_2.0/seperated_test_data.csv\"\n",
    "output_path_2 = \"../../data/Prompt_Training_2.0/labeled_test_data.csv\"\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(validation_data_path):\n",
    "    print(f\"Error: File {validation_data_path} not found.\")\n",
    "else:\n",
    "    # Load the data\n",
    "    df = pd.read_csv(validation_data_path)\n",
    "    test_df = pd.read_csv(testing_data_path)\n",
    "    print(f\"Loaded {len(df)} rows from validation data.\")\n",
    "    \n",
    "    # Create a new column for improved prompts\n",
    "    df['improved_prompt'] = None\n",
    "    test_df['improved_prompt'] = None\n",
    "    \n",
    "    # Process each row\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Generating improved prompts\"):\n",
    "        instruction = row['instruction']\n",
    "        context = row['context']\n",
    "        \n",
    "        try:\n",
    "            # Generate improved prompt\n",
    "            improved_prompt = generate_response(instruction, context)\n",
    "            df.at[idx, 'improved_prompt'] = improved_prompt\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx}: {e}\")\n",
    "            df.at[idx, 'improved_prompt'] = f\"Error: {str(e)}\"\n",
    "\n",
    "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Generating improved prompts\"):\n",
    "        instruction = row['instruction']\n",
    "        context = row['context']\n",
    "        \n",
    "        try:\n",
    "            # Generate improved prompt\n",
    "            improved_prompt = generate_response(instruction, context)\n",
    "            test_df.at[idx, 'improved_prompt'] = improved_prompt\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx}: {e}\")\n",
    "            test_df.at[idx, 'improved_prompt'] = f\"Error: {str(e)}\"\n",
    "\n",
    "    # Save the results\n",
    "    df.to_csv(output_path, index=False)\n",
    "    test_df.to_csv(output_path_2, index=False)\n",
    "    print(f\"Saved results to {output_path}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Post Processing\n",
    "\n",
    "- Ensure data quality by manually going through each improved prompt and response and removing any malformed responses\n",
    "\n",
    "## 4. Export data for fine tuning in Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Load the final datasets \n",
    "validation_df = pd.read_csv('../data/Prompt_Training_2.0/labeled_validation_final.csv')\n",
    "train_df = pd.read_csv('../data/Prompt_Training_2.0/labeled_train_final.csv')\n",
    "\n",
    "# Build the prompt template \n",
    "prompt_template = \"\"\"You are a prompt engineering expert.\n",
    "\n",
    "Your task is to rewrite the instruction below using advanced prompt engineering techniques. If context is provided, use it as *background knowledge* to better understand the task — but do not include it in the final output.\n",
    "\n",
    "Guidelines:\n",
    "- Enhance the instruction to be clearer, more specific, and more effective\n",
    "- Use any prompting technique that best fits\n",
    "- Ground your rewrite in the provided context, if applicable\n",
    "- Do NOT copy or reference the context in your rewritten instruction\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Original Instruction:\n",
    "{instruction}\n",
    "\n",
    "Output ONLY the improved instruction without any additional text, titling, explanations, or acknowledgment.\"\"\"\n",
    "\n",
    "# Function to create JSONL entries\n",
    "def create_jsonl_entries(df, include_system_prompt=False):\n",
    "    entries = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # Format the prompt with the template\n",
    "        context = row['context'] if pd.notna(row['context']) else \"\"\n",
    "        instruction = row['instruction'] if pd.notna(row['instruction']) else \"\"\n",
    "        improved = row['improved_instruction'] if pd.notna(row['improved_instruction']) else \"\"\n",
    "        \n",
    "        formatted_prompt = prompt_template.format(context=context, instruction=instruction)\n",
    "        \n",
    "        # Create the entry based on whether to include system prompt\n",
    "        if include_system_prompt:\n",
    "            entry = {\n",
    "                \"systemInstruction\": {\n",
    "                    \"role\": \"system\", \n",
    "                    \"parts\": [{\"text\": \"You are a prompt engineering expert that transforms prompts into more effective versions.\"}]\n",
    "                }, \n",
    "                \"contents\": [\n",
    "                    {\n",
    "                        \"role\": \"user\", \n",
    "                        \"parts\": [{\"text\": formatted_prompt}]\n",
    "                    }, \n",
    "                    {\n",
    "                        \"role\": \"model\", \n",
    "                        \"parts\": [{\"text\": improved}]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        else:\n",
    "            entry = {\n",
    "                \"contents\": [\n",
    "                    {\n",
    "                        \"role\": \"user\", \n",
    "                        \"parts\": [{\"text\": formatted_prompt}]\n",
    "                    }, \n",
    "                    {\n",
    "                        \"role\": \"model\", \n",
    "                        \"parts\": [{\"text\": improved}]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        \n",
    "        entries.append(entry)\n",
    "    \n",
    "    return entries\n",
    "\n",
    "# Create JSONL entries for training and validation\n",
    "train_entries = create_jsonl_entries(train_df, include_system_prompt=False)\n",
    "validation_entries = create_jsonl_entries(validation_df, include_system_prompt=False)\n",
    "\n",
    "# Save to JSONL files\n",
    "train_jsonl_path = '../data/Prompt_Training_2.0/vertex_ai_fine_tuning_train.jsonl'\n",
    "validation_jsonl_path = '../data/Prompt_Training_2.0/vertex_ai_fine_tuning_validation.jsonl'\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(os.path.dirname(train_jsonl_path), exist_ok=True)\n",
    "\n",
    "# Write training data\n",
    "with open(train_jsonl_path, 'w') as f:\n",
    "    for entry in train_entries:\n",
    "        f.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "# Write validation data\n",
    "with open(validation_jsonl_path, 'w') as f:\n",
    "    for entry in validation_entries:\n",
    "        f.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "print(f\"Created training JSONL file at {train_jsonl_path}\")\n",
    "print(f\"Total training examples: {len(train_entries)}\")\n",
    "\n",
    "print(f\"Created validation JSONL file at {validation_jsonl_path}\")\n",
    "print(f\"Total validation examples: {len(validation_entries)}\")\n",
    "\n",
    "# Display a sample entry\n",
    "print(\"\\nSample entry:\")\n",
    "print(json.dumps(train_entries[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test new model api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../env.json', 'r') as f:\n",
    "    env_vars = json.load(f)\n",
    "# Set environment variables from the loaded file\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = env_vars[\"google_cloud_project\"]\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = env_vars[\"google_cloud_location\"]\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = env_vars[\"google_genai_use_vertexai\"]\n",
    "# Set the fine-tuned model ID as an environment variable\n",
    "os.environ[\"FINE_TUNED_MODEL_ID\"] = env_vars[\"fine_tuned_v2_model_id\"]\n",
    "\n",
    "\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai.types import HttpOptions\n",
    "\n",
    "# Initialize the GenAI client for Vertex AI\n",
    "client = genai.Client(http_options=HttpOptions(api_version=\"v1\"))\n",
    "\n",
    "# Define a test prompt\n",
    "instruction = \"Write a function to calculate the Fibonacci sequence in Python\"\n",
    "context = \"The Fibonacci sequence is a series of numbers where each number is the sum of the two preceding ones, usually starting with 0 and 1.\"\n",
    "\n",
    "test_prompt = prompt_template.format(context=context, instruction=instruction)\n",
    "\n",
    "# Call the fine-tuned model\n",
    "response = client.models.generate_content(\n",
    "    model=os.environ[\"FINE_TUNED_MODEL_ID\"],\n",
    "    contents=test_prompt,\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(\"Original prompt:\")\n",
    "print(test_prompt)\n",
    "print(\"\\nImproved prompt from fine-tuned model:\")\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
