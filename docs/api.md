# API Documentation

## Overview

The One-Prompted API provides access to fine-tuned prompt enhancement models through a simple REST API. The service is built on a fine-tuned Gemini-based model deployed on Google Vertex AI.

## Base URL

```
https://api.oneprompted.com
```

## Endpoints

### Generate Enhanced Prompts

```
POST /generate
```

Transforms a simple prompt into an enhanced, more effective version using the fine-tuned prompt enhancement model.

#### Request Body

```json
{
  "input": "Your original prompt text here"
}
```

| Field | Type | Description |
|-------|------|-------------|
| `input` | string | The original prompt text to be enhanced |

#### Response

```json
{
  "output": "Enhanced prompt text"
}
```

| Field | Type | Description |
|-------|------|-------------|
| `output` | string | The enhanced prompt generated by the model |

#### Error Responses

| Status Code | Description |
|-------------|-------------|
| 400 | Bad Request - Missing or invalid input |
| 429 | Too Many Requests - Daily request limit reached (100 requests per day) |
| 500 | Internal Server Error - Error occurred during model inference |

#### Example

Request:
```json
{
  "input": "Write a blog post about machine learning"
}
```

Response:
```json
{
  "output": "Compose a comprehensive 800-1000 word blog post titled 'The Evolution and Future of Machine Learning: From Theory to Practice.' Structure the post with the following sections: 1) An introduction explaining what machine learning is and its significance in today's technological landscape; 2) A brief history of machine learning, highlighting key milestones and breakthroughs; 3) Current real-world applications across 3-4 diverse industries; 4) Challenges and ethical considerations; 5) Future trends and predictions for the next 5 years; and 6) A conclusion with actionable insights for businesses considering implementing ML solutions. Include relevant statistics, examples, and maintain an informative yet accessible tone suitable for a technically curious but non-expert audience."
}
```

### Health Check

```
GET /ping
```

Simple endpoint to check if the API is running.

#### Response

```json
{
  "status": "ok"
}
```

## Rate Limits

- 100 requests per day
- Rate limit is reset daily at midnight UTC

## Technical Implementation

The API is built using:

- FastAPI framework for the REST API
- Vertex AI for hosting the fine-tuned Gemini model
- Google Cloud Firestore for tracking API usage and rate limiting
- Docker for containerization

## Deployment

The API is containerized using Docker and can be deployed on any infrastructure that supports Docker containers.

```bash
# Build the Docker image
docker build -t oneprompted-api .

# Run the container
docker run -p 8080:8080 oneprompted-api
```

## Security

The API uses Google Cloud service account credentials for authentication with Vertex AI and Firestore. The service account credentials are stored in an `env.json` file that should be kept secure and not committed to version control.

## Error Handling

The API implements proper error handling for:
- Missing or invalid input
- Daily request limit exceeded
- Model inference errors

All errors are returned with appropriate HTTP status codes and descriptive messages.
