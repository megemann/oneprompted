# V2

## labeled_train_final.csv & labeled_validation_final.csv

These datasets contain prompt improvement examples used for training and validation from the ShareGPT 52k Dataset. Each example consists of:

- **original_prompt**: The initial prompt submitted by a user
- **context**: Additional information provided (may be empty)
- **instruction**: The original instruction/prompt
- **improved_instruction**: A higher-quality rewritten version of the instruction

The improved instructions demonstrate best practices in prompt engineering, including:
- Clear role definitions
- Specific task descriptions
- Structured output formatting
- Appropriate constraints and guidelines
- Removal of ambiguity

### Example Use Cases
- Training models to improve prompt quality
- Studying effective prompt engineering techniques
- Benchmarking prompt improvement capabilities

### Format
CSV files with 4 columns (original_prompt, context, instruction, improved_instruction)

### Statistics
- **labeled_train_final.csv**: Training dataset
- **labeled_validation_final.csv**: Validation dataset

## separated_test_data.csv, separated_train_data.csv, separated_validation_data.csv

These datasets contain prompt examples separated into different sets for training, validation, and testing. Each example consists of:

- **original_prompt**: The initial prompt submitted by a user
- **context**: Additional information provided (may be empty)
- **instruction**: The core instruction/request
- **has_context**: Boolean flag indicating whether context is present
- **conversation_id**: Unique identifier for the conversation

### Example Use Cases
- Training and evaluating prompt understanding models
- Analyzing prompt patterns with and without context
- Benchmarking instruction following capabilities

### Format
CSV files with 5 columns (original_prompt, context, instruction, has_context, conversation_id)

### Data Collection Methodology
The dataset was created by extracting approximately 1,000 examples from the ShareGPT 52k dataset, which contains conversations between users and ChatGPT. The preprocessing steps included:

1. Filtering to include only English language messages
2. Selecting only the first prompt from each conversation to ensure they had no prior context
3. Manual separation of each prompt into context and instruction components

### Statistics
- **separated_test_data.csv**: Test dataset for final evaluation
- **separated_train_data.csv**: Primary training dataset for tuning
- **separated_validation_data.csv**: Validation dataset for model tuning

### Context vs. Instruction Separation Guidelines
The manual separation process followed these definitions:

**Context**: 
- Factual information, examples, or constraints that provide background knowledge
- Content that should remain unchanged during prompt engineering
- Examples include: code snippets, school problems, articles, or reference materials

**Instruction**: 
- The portion of the prompt intended to be improved through engineering
- Contains specific directives, role assignments, or output requirements
- Examples include: role assignments for the model, action verbs like "summarize" or "debug", and specific output format requirements